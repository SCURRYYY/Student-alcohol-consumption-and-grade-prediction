ggplot(aes(x=color), data=na.omit(diamondsByColor))  +
geom_bar(stat='count')
library(gridExtra)
p1=ggplot(aes(x=color), data=na.omit(diamondsByColor))  +
geom_bar(stat='count')
p2=ggplot(aes(x=clarity), data=na.omit(diamondsByClarity))  +
geom_bar(stat='count')
grid.arrange(p1,p2,ncol=1)
p1=ggplot(aes(x=color,y=mean_price), data=na.omit(diamondsByColor))  +
geom_col()
p1
p1=ggplot(aes(x=color,y=mean_price), data=na.omit(diamondsByColor))  +
geom_col(binwidth=10)
p1
p1=ggplot(aes(x=color,y=mean_price), data=na.omit(diamondsByColor))  +
geom_col(binwidth=5)
p2=ggplot(aes(x=clarity), data=na.omit(diamondsByClarity))  +
geom_col()
p2
p1=ggplot(aes(x=color,y=mean_price), data=na.omit(diamondsByColor))  +
geom_col()
p2=ggplot(aes(x=clarity,y=mean_price), data=na.omit(diamondsByClarity))  +
geom_col()
grid.arrange(p1,p2,ncol=1)
diamondsByColor<- diamonds %>% group_by(color) %>%
summarise(mean_price = mean(price), median_price=median(price) , min_price=min(price),max_price=max(price) , sum_price=sum(price), count=n())
diamondsByClarity<- diamonds %>% group_by(clarity) %>%
summarise(mean_price = mean(price) , median_price = median(price), min_price=min(price), max_price=max(price),sum_price=sum(price),n = n())
View(diamondsByClarity)
p1=ggplot(aes(x=color,y=mean_price), data=na.omit(diamondsByColor))  +
geom_bar()
p1
fb
ggplot(aes(x=cut , y = ratio_ppc), data = diamonds)  +
geom_point(aes(color=color)) +
scale_color_brewer(type = 'div') +
facet_wrap(~ clarity) +
coord_trans(y = 'sqrt')
library(ggplot2)
ggplot(aes(x=cut , y = ratio_ppc), data = diamonds)  +
geom_point(aes(color=color)) +
scale_color_brewer(type = 'div') +
facet_wrap(~ clarity) +
coord_trans(y = 'sqrt')
diamonds<-mutate(diamonds, ratio_ppc = price/carat)
library(dplyr)
diamonds<-mutate(diamonds, ratio_ppc = price/carat)
ggplot(aes(x=cut , y = ratio_ppc), data = diamonds)  +
geom_point(aes(color=color)) +
scale_color_brewer(type = 'div') +
facet_wrap(~ clarity) +
coord_trans(y = 'sqrt')
ggplot(aes(x=cut , y = ratio_ppc), data = diamonds)  +
geom_line(aes(color=color)) +
scale_color_brewer(type = 'div') +
facet_wrap(~ clarity) +
coord_trans(y = 'sqrt')
ggplot(aes(x=cut , y = ratio_ppc), data = diamonds)  +
geom_point() +
geom_point(aes(color=color)) +
scale_color_brewer(type = 'div') +
facet_wrap(~ clarity)
install.packages('memisc')
#for Scatterplot  matrices - and r
library(GGally)#scatterplot matrices
library(memisc)#to summarise the regression
library(scales)#for writing things
library(MASS)
library(car)
diamonds_samp<- diamonds[sample(nrow(diamonds),10000) , ]
View(diamonds_samp)
ggpairs(diamonds_samp)
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 10,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 10 , color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1
p1=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = 10) +
geom_histogram(color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = 10 ) +
geom_histogram( color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(GGally)#scatterplot matrices
library(memisc)#to summarise the regression
library(scales)#for writing things
library(MASS)
library(car)
library(ggplot2)
p1=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = 10) +
geom_histogram(color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = 10 ) +
geom_histogram( color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = .01) +
geom_histogram(color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = .01 ) +
geom_histogram( color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = 100) +
geom_histogram(color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds),binwidth = .01 ) +
geom_histogram( color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 100,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = .10,color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 100,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#binwidth is basically width or interval of 1 bin (group)
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = .01,color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=1)
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 1000,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
p1
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 100,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#binwidth is basically width or interval/size  of 1 bin-bucket (group)
#lesser binwidth more accurate counts
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = .01,color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , nrow=2)
p1=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = 100,color=I('black'), fill = I('yellow')) +
ggtitle('Not Normalized')
#this one looks long-tailed
#binwidth is basically width or interval/size  of 1 bin-bucket (group)
#lesser binwidth more accurate counts
#lognormal distribution- scale_x_log10
p2=ggplot(aes(x = price), data = na.omit(diamonds)) +
geom_histogram(binwidth = .01,color=I('black'), fill = I('red')) +
scale_x_log10() +
ggtitle('Lognormal Distribution for Normalizing data')
library(gridExtra)
grid.arrange(p1,p2 , ncol=2)
library(ggplot2)
data('diamonds')
library(GGally)#scatterplot matrices
library(memisc)#to summarise the regression
library(scales)#for writing things
library(MASS)
library(car)
source('~/RStudio/explored datasets/daimonds.R', echo=TRUE)
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point(alpha= 1/4) +
geom_smooth(method = 'glm',color='red')+
scale_color_brewer(type = 'div')
cube_root<- function() trans_new('cuberoot',
transform = function(x) x^(1/3) ,
inverse = function(x) x^3)
?trans_new
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point() +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div')
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point() +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div')
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point() +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div')  +
geom_smooth(method = 'glm',color='red')
head(table(diamonds$carat))
head(sort(table(diamonds$carat),decreasing = T))
head(sort(table(diamonds$carat),decreasing = F))
head(sort(table(diamonds$price),decreasing = F))
head(sort(table(diamonds$price),decreasing = T))
head(sort(count(diamonds$price),decreasing = T))
library(tidyr)
head(sort(count(diamonds$price),decreasing = T))
head(sort(count(diamonds$price),decreasing = T))
?count
library(dplyr)
head(sort(count(diamonds$price),decreasing = T))
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point(alpha=1/2 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div')
ggplot(aes(x = carat ,  y = price,color = cut), data =na.omit(diamonds)) +
geom_point(alpha=1/2 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000))
ggplot(aes(x = carat ,  y = price), data =na.omit(diamonds)) +
geom_point(alpha=1/2 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000))
ggplot(aes(x = carat ,  y = price), data =na.omit(diamonds)) +
geom_point(alpha=1/5 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000))
library(RColorBrewer)
ggplot(aes(x = carat ,  y = price,color=clarity), data =na.omit(diamonds)) +
geom_point(alpha=1/5 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div',guide = guide_legend(title = 'Clarity'), reverse=T)
ggplot(aes(x = carat ,  y = price,color=clarity), data =na.omit(diamonds)) +
geom_point(alpha=1/5 , size = 3/4 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div',guide = guide_legend(title = 'Clarity', reverse=T))
ggplot(aes(x = carat ,  y = price,color=clarity), data =na.omit(diamonds)) +
geom_point(alpha=1/2 , size = 2 , position = 'jitter') +
#x-axes transformed to cuberoot-volume
scale_x_continuous(trans = cube_root(), limits = c(0.2,3) , breaks = c(0.2,0.5,1,2,3)) +
#transforming y i.e price lognormally-due to wide range of value-spread
scale_y_continuous(limits = c(350,15000 ) , trans=log10_trans() , breaks=c(250,1000,5000,10000,15000)) +
scale_color_brewer(type = 'div',guide = guide_legend(title = 'Clarity', reverse=T))
summary(diamonds$clarity)
install.packages('twitteR')
library(twitteR)
demoney<-searchTwitter('#demoneytization', n =100)
api_key <- "Uljbn9QiCceg6AWbJ5LckZYoB"
api_secret <- "	Ql3tkU5bIGTjxC1fZbT2OCuKl21EBbOkMFv0BSeF1KnaEzyKGL"
access_token <- "830571150036103168-5dPNc0uaXLD12QJba5DtX4rMEBcISB5"
access_token_secret <- "	lIABRUsfELuuSbPTlo7rZ2gI5vADHDqXVi3JfYtMILoGJ"
demoney<-searchTwitter('#demoneytization', n =100)
searchTwitter("iphone")
library(twitteR)
install_github("twitteR", username="geoffjentry")
library(twitteR)
api_key <- "Uljbn9QiCceg6AWbJ5LckZYoB"
api_secret <- "	Ql3tkU5bIGTjxC1fZbT2OCuKl21EBbOkMFv0BSeF1KnaEzyKGL"
access_token <- "830571150036103168-5dPNc0uaXLD12QJba5DtX4rMEBcISB5"
access_token_secret <- "	lIABRUsfELuuSbPTlo7rZ2gI5vADHDqXVi3JfYtMILoGJ"
demoney<-searchTwitter('#demoneytization', n =100)
api_key <- "	hvaamlxy730zlRDXqLnkYa2N5"
api_secret <- "Wi5zYV7txtro3lhm4M1k3xxgGMV86NwADjKlgWbQgod7IBRSfI"
access_token <- "830571150036103168-5dPNc0uaXLD12QJba5DtX4rMEBcISB5"
access_token_secret <- "lIABRUsfELuuSbPTlo7rZ2gI5vADHDqXVi3JfYtMILoGJ"
demoney<-searchTwitter('#demoneytization', n =100)
demoney<-searchTwitter('#demoneytization', n =100,api_key)
?searchTwitter()
getTwitterOAuth(api_key, api_secret)
registerTwitterOAuth(oauth)
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
demoney<-searchTwitter('#demoneytization', n =100)
setup_twitter_oauth(api_key, api_secret, access_token=access_token, access_secret=access_token_secret)
setup_twitter_oauth(api_key=api_key, api_secret=api_secret, access_token=access_token, access_secret=access_token_secret)
api_key <- "	hvaamlxy730zlRDXqLnkYa2N5"
api_secret <- "Wi5zYV7txtro3lhm4M1k3xxgGMV86NwADjKlgWbQgod7IBRSfI"
access_token <- "830571150036103168-5dPNc0uaXLD12QJba5DtX4rMEBcISB5"
access_token_secret <- "lIABRUsfELuuSbPTlo7rZ2gI5vADHDqXVi3JfYtMILoGJ"
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
setup_twitter_oauth("hvaamlxy730zlRDXqLnkYa2N5", "Wi5zYV7txtro3lhm4M1k3xxgGMV86NwADjKlgWbQgod7IBRSfI", "830571150036103168-5dPNc0uaXLD12QJba5DtX4rMEBcISB5", "lIABRUsfELuuSbPTlo7rZ2gI5vADHDqXVi3JfYtMILoGJ")
api_key <- "hvaamlxy730zlRDXqLnkYa2N5"
api_secret <- "Wi5zYV7txtro3lhm4M1k3xxgGMV86NwADjKlgWbQgod7IBRSfI"
access_token <- "	830571150036103168-R1Ly6IGNcbb9WQ3cWQSxxcWn01e6DXX"
access_token_secret <- "gYTOmsRO6GGNJV5NQWc0SZ1xrEty3wIaOOV5I6OdZxobM"
setup_twitter_oauth(api_key,api_secret)
demoney<-searchTwitter('#demoneytization', n =100)
demoney
length(demoney)
demoney<-searchTwitter('@demoneytisation', n =100)
demoney<-searchTwitter('@delta', n =100)
length(demoney)
airline<-searchTwitter('@jetairways', n =100)
length(airline)
rm(demoney)
airline[[1]]
airline[[2]]
airline[[3]]
airline[[5:20]]
airline[[5]]
airline[[5]]$getScreenName()
airline[[20]]$getScreenName()
airline[[20]]
airline[[100]]$getScreenName()
airline[[100]]
airline.text<-laply(airline , function(t) t$getText() )
airline.text<-lapply(airline , function(t) t$getText() )
airline.text[2]
airline.text<-as.data.frame(airline.text)
View(airline.text)
airline.text<-as.dataframe(airline.text)
rm(airline.text)
airline.text<-lapply(airline , function(t) t$getText() )
airline_tweets<-data.fame(Tweets=airline_text)
airline_tweets<-data.frame(Tweets=airline_text)
airline_tweets<-data.frame(Tweets=airline.text)
View(airline_tweets)
rm(airline_tweets)
?score.sentiment
setwd('F:/PROJECTS/EDA-PROJECT/')
stu<-read.csv('student-mat.csv')
#loading essential packages
library(ggplot2)
library(dplyr)
library(tidyr)
require(rpart)
require(rpart.plot)
model1<-rpart(G3 ~ . , data = stur[1:150,])
library(C50)
set.seed(9850)
g<-runif(nrow(stu))
#Random and shuffled student dataset
stur<-stu[order(g) , ]
model1<-rpart(G3 ~ . , data = stur[1:150,])
model1
summary(model1)
fancyRpartPlot(model1)
library(rattle)
fancyRpartPlot(model1)
p1<-predict(model1,newdata=stur[200:350,])
accuracy<-cbind(actual=stur[200:350,33],predicted=p1)
acc1<-as.data.frame(accuracy)
View(acc1)
summary(acc1$predicted)
summary(acc1$actual)
acc1<-mutate(acc1,residuals = actual - predicted)
#standerdized residuals-residual values divided by sd of residuals
acc1<-mutate(acc1,Stdresid = residuals/sd(residuals))
model2<-rpart(G3 ~ goout + absences + studytime + Dalc + Walc + famsup , data = stur[200:350,])
gini
Gini
loss
predict(model2,newdata=data.frame(goout = 5 ,absences = 80 , Walc = 4, Dalc = 4 , famsup = "yes",studytime=3))
predict(model2,newdata=data.frame(goout = 5 ,absences = 80 , Walc = 4, Dalc = 4 , famsup = "yes",studytime=1))
summary(model2)
predict(model2,newdata=data.frame(goout = 2 ,absences = 90 , Walc = 4, Dalc = 4 , famsup = "no",studytime=1))
predict(model2,newdata=data.frame(goout = 2 ,absences = 90 , Walc = 2, Dalc = 1 , famsup = "no",studytime=1))
predict(model2,newdata=data.frame(goout = 1 ,absences = 10 , Walc = 2, Dalc = 1 , famsup = "no",studytime=5))
predict(model2,newdata=data.frame(goout = 1 ,absences = 10 , Walc = 2, Dalc = 1 , famsup = "no",studytime=4))
predict(model2,newdata=data.frame(goout = 1 ,absences = 10 , Walc = 5, Dalc = 4 , famsup = "no",studytime=4))
C5.0(G3~. , data = stur[1:150,])
C5.0(as.factor(G3) ~. , data = stur[1:150,])
model3<-C5.0(as.factor(G3) ~. , data = stur[1:150,])
summary(model3)
fancyRpartPlot(model3)
plot(model3)
library(partykit)
plot(model3)
plot(model3[16])
myTree2 <- C50:::as.party.C5.0(model3)
plot(mytree2[16])
plot(myTree2[16])
plot(myTree2[16:30])
plot(myTree2[2])
plot(myTree2[10])
p2<-predict(model3,newdata = stur[200:350,])
view(p2)
summmary(residuals(model3))
summary(residuals(model3))
model3<-C5.0(G3 ~. , data = stur[1:150,])
model3<-C5.0(as.factor(Walc) ~. , data = stur[1:150,])
plot(model3)
p2<-predict(model3,newdata = stur[200:350,])
summary(residuals(model3))
resid(model3)
summary(model3)
6/25*100
6/31
25/32
View(stur)
acc2<-cbind(Actual=stur[200:350,28], Predicted = p2)
View(acc2)
acc2<-as.data.frame(cbind(Actual=stur[200:350,28], Predicted = p2))
table(actual=stur[200:350,28],predicted= p2)
t1<-table(actual=stur[200:350,28],predicted= p2)
dim(t1)
62/151
ggplot(aes(x=Actual, y=Predicted), data = acc2) +
geom_point()
acc2<-as.data.frame(cbind(Actual=stur[200:350,25:28], Predicted = p2))
acc2<-as.data.frame(cbind(Actual=stur[200:350,25:28], Predicted.Walc = p2))
filter(acc2, Predicted.Walc==Actual.Walc)
filter(acc2, Predicted.Walc!=Actual.Walc)
ggplot(aes(x=Actual, y=Predicted), data = acc2) +
geom_jitter()
ggplot(aes(x=Actual.Walc, y=Predicted.Walc), data = acc2) +
geom_jitter()
ggplot(aes(x=Actual.Walc, y=Predicted.Walc), data = acc2) +
geom_jitter() +
geom_smooth()
acc2 %>% mutate(error_diff = Actual.Walc - Predicted.Walc)
acc2 %>% mutate(acc2,error_diff = Actual.Walc - Predicted.Walc)
acc2<-mutate(acc2,error_diff = Actual.Walc - Predicted.Walc)
acc2<-mutate(acc2,error_diff = as.integer(Actual.Walc - Predicted.Walc))
acc2<-mutate(acc2,error_diff = as.numeric(Actual.Walc - Predicted.Walc))
acc2<-mutate(acc2, as.numeric(Actual.Walc, Predicted.Walc))
rm(acc2$error_diff,acc2$as.numeric(Actual.Walc, Predicted.Walc))
rm(acc2$error_diff)
rm(acc2$'error_diff')
acc2<-as.data.frame(cbind(Actual=stur[200:350,25:28], Predicted.Walc = p2))
acc2<-transform(acc2,as.numeric(Actual.Walc,Predicted.Walc))
acc2<-transform(acc2, Error_diff = Actual.Walc -  Predicted.Walc)
typeof(acc2$Actual.Walc)
typeof(acc2$Predicted.Walc.Walc)
typeof(acc2$Predicted.Walc)
as.numeric(acc2$Actual.Walc)
as.numeric(acc2$Predicted.Walc)
acc2<-transform(acc2, Error_diff = Actual.Walc -  Predicted.Walc)
acc2<-transform(acc2,as.numeric(Predicted.Walc))
acc2<-transform(acc2,as.integer(Predicted.Walc))
acc2<-as.data.frame(cbind(Actual=stur[200:350,25:28], Predicted.Walc = p2))
ggplot(aes(x = Predicted.Walc),data = acc2) +
geom_bar()
ggplot(aes(x = Actual.Walc),data = acc2) +
geom_bar()
View(d)
model4<-rpart(failures ~ .  ,data = stur[1:250,], method = 'class')
model4
summary(model4)
model5<-C5.0(failures ~ .  ,data = stur[1:250,])
model5<-C5.0(as.factor(failures) ~ .  ,data = stur[1:250,])
model5
summary(model5)
plot(model5)
fancyRpartPlot(model4)
model4<-rpart(failures ~ .  ,data = stur[1:250,])
model4
summary(model4)
fancyRpartPlot(model4)
rm(model5)
rpart.plot(model4)
printcp(model4)
pruned_model4<-prune(model4,cp)
pruned_model4<-prune(model4)
printcp(model4)
?prune
pruned_model4<-prune(model4,cp=min(cp))
pruned_model4<-prune(model4,cp=0.0167)
rpart.plot(pruned_model4)
summary(pruned_model4)
pruned_predict<-predict(pruned_model4 , newdata = stur[251:350,15])
pruned_predict<-predict(pruned_model4 , newdata = stur[251:320,15])
pruned_predict<-predict(pruned_model4 , newdata = stur[251:351,])
summary(residuals(pruned_model4))
ggplot(aes(x = residuals(model4)))
plot(resid(pruned_model4))
hist(resid(pruned_model4))
acc3<-as.data.frame(cbind(actual=stur[51:351,15], predicted=pruned_predict))
acc3<-as.data.frame(cbind(actual=stur[251:351,15], predicted=pruned_predict))
View(acc3)
summary(acc3$actual)
summary(acc3$predicted)
model4<-rpart(failures ~ .  ,data = stur[1:250,],method='anova')
fancyRpartPlot(model4)
pruned_model4<-prune(model4,cp=0.0167)
rpart.plot(pruned_model4)
predict(pruned_model4,data.frame(age=18,G1=18,Mjob='teacher',sex='M'))
